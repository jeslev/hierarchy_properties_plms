{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77763d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer, BertModel, BertTokenizer, \\\n",
    "                         BertConfig, RobertaForSequenceClassification,RobertaTokenizer\n",
    "\n",
    "import fasttext\n",
    "\n",
    "\n",
    "from evaluation.extract_representations import get_dataset, get_embeddings_from_model\n",
    "logging.basicConfig(format='%(process)d-%(levelname)s-%(message)s')\n",
    "\n",
    "\n",
    "\n",
    "def get_vocab_from_jsondf(inputfile, basepath):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        inputfile: Input file path\n",
    "        Basepath: Data folder\n",
    "    Returns:\n",
    "        lvocab: List of vocabulary in the dataset\n",
    "    The function reads the dataframe from the inputfile. Then, it recovers the unique triplets\n",
    "    (tree_id, node name, node definition) as a list.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_json(load_json(os.path.join(basepath,inputfile)), orient=\"index\")\n",
    "    # Iterate by subtrees, create directed graph + collect definitions\n",
    "    all_vocab = {} # key:value -> (id_tree): {definitions:{}, graph:}\n",
    "    for tid in range(min(df[\"treeid\"]), max(df[\"treeid\"])+1):\n",
    "        # For each subtree\n",
    "        filtered_df = df[df[\"treeid\"]==tid]\n",
    "        #print(display(filtered_df))\n",
    "        # Retrieve definitions in this subtree\n",
    "        for idx,row in filtered_df.iterrows():\n",
    "            all_vocab[str(tid)+\"-\"+row['father']]=[tid,row['father'],row['father_definition']]\n",
    "            all_vocab[str(tid)+\"-\"+row['child']]=[tid, row['child'],row['child_definition']]\n",
    "\n",
    "        #subtrees[tid] = {'definitions':dictionary_defs, 'graph':G}\n",
    "        #print(\"Root\", [n for n,d in G.in_degree() if d==0] )\n",
    "    lvocab =[]\n",
    "    for k,v in all_vocab.items():\n",
    "        lvocab.append(v)\n",
    "    \n",
    "    return lvocab\n",
    "\n",
    "\n",
    "\n",
    "def get_dataset(inputfile, dataset_path):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        inputfile: json file\n",
    "        dataset_path: path for the data folder\n",
    "\n",
    "    Returns:\n",
    "        Dataset (from HuggingFaces).\n",
    "    It adds a new column with the constructed phrase with a word and its definition.\n",
    "    \"\"\"\n",
    "\n",
    "    _all_vocab = get_vocab_from_jsondf(inputfile, dataset_path)\n",
    "    df = pd.DataFrame(_all_vocab, columns=['tid','name','definition'])\n",
    "    #df['name'] = df['name'].str.lower()\n",
    "    #df['definition'] = df['definition'].str.lower()\n",
    "    dataset = Dataset.from_pandas(df)\n",
    "    dataset= dataset.add_column('concept',[n+\" is defined as \"+d for n,d in zip(dataset['name'],dataset['definition'])])\n",
    "    #print(\"Loaded dataset\")\n",
    "    #print(dataset)\n",
    "    return dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca719c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ifile =\n",
    "_dataset_base = \n",
    "\n",
    "logging.info(\"Reading dataset.\")\n",
    " _dataset = get_dataset(_ifile, _dataset_base)\n",
    "    \n",
    "logging.info(f\"Processing model: {model_name} with file: {_ifile}.\")\n",
    "get_embeddings_from_model(_dataset, model_str=model_name,model_src=model_source,\n",
    "                          column=input_type,output_path=_output_name,only_last_layer=only_last_layer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
