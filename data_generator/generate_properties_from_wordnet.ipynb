{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc312c79",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check if multiple definitions are present.\n",
      "Total words 15634 . Words with more than 1 definition  0\n",
      "########    train  ###########\n",
      "Number of entries:  10364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-a31ad0ad574a>:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_bansal_df[\"father\"] = filtered_bansal_df[\"father\"].apply(lambda x: x.replace(\"_$_\", \" \"))\n",
      "<ipython-input-2-a31ad0ad574a>:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_bansal_df[\"child\"] = filtered_bansal_df[\"child\"].apply(lambda x: x.replace(\"_$_\", \" \"))\n",
      "<ipython-input-2-a31ad0ad574a>:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_bansal_df[\"father_definition\"] = father_defs\n",
      "<ipython-input-2-a31ad0ad574a>:86: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_bansal_df[\"child_definition\"] = child_defs\n",
      "<ipython-input-2-a31ad0ad574a>:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_bansal_df[\"father\"] = filtered_bansal_df[\"father\"].apply(lambda x: x.replace(\"_$_\", \" \"))\n",
      "<ipython-input-2-a31ad0ad574a>:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_bansal_df[\"child\"] = filtered_bansal_df[\"child\"].apply(lambda x: x.replace(\"_$_\", \" \"))\n",
      "<ipython-input-2-a31ad0ad574a>:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_bansal_df[\"father_definition\"] = father_defs\n",
      "<ipython-input-2-a31ad0ad574a>:86: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_bansal_df[\"child_definition\"] = child_defs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        father              child  treeid  split  \\\n",
      "0  working dog           watchdog       0  train   \n",
      "1  working dog  seizure-alert dog       0  train   \n",
      "2  working dog        Sennenhunde       0  train   \n",
      "3  working dog         Eskimo dog       0  train   \n",
      "4  working dog         Great Dane       0  train   \n",
      "\n",
      "                                   father_definition  \\\n",
      "0  any of several breeds of usually large powerfu...   \n",
      "1  any of several breeds of usually large powerfu...   \n",
      "2  any of several breeds of usually large powerfu...   \n",
      "3  any of several breeds of usually large powerfu...   \n",
      "4  any of several breeds of usually large powerfu...   \n",
      "\n",
      "                                    child_definition  \n",
      "0                    a dog trained to guard property  \n",
      "1  a dog that can alert or assist people with sei...  \n",
      "2                           any of four Swiss breeds  \n",
      "3              breed of heavy-coated Arctic sled dog  \n",
      "4     very large powerful smooth-coated breed of dog  \n",
      "########    dev  ###########\n",
      "Number of entries:  2282\n",
      "             father         child  treeid split  \\\n",
      "10364   elimination  incontinence     533   dev   \n",
      "10365   elimination    defecation     533   dev   \n",
      "10366   elimination   micturition     533   dev   \n",
      "10367  incontinence      enuresis     533   dev   \n",
      "10368      enuresis   bed-wetting     533   dev   \n",
      "\n",
      "                                       father_definition  \\\n",
      "10364     the bodily process of discharging waste matter   \n",
      "10365     the bodily process of discharging waste matter   \n",
      "10366     the bodily process of discharging waste matter   \n",
      "10367                involuntary urination or defecation   \n",
      "10368  inability to control the flow of urine and inv...   \n",
      "\n",
      "                                        child_definition  \n",
      "10364                involuntary urination or defecation  \n",
      "10365    the elimination of fecal waste through the anus  \n",
      "10366                             the discharge of urine  \n",
      "10367  inability to control the flow of urine and inv...  \n",
      "10368  enuresis during sleep; especially common in ch...  \n",
      "########    test  ###########\n",
      "Number of entries:  2226\n",
      "          father      child  treeid split  \\\n",
      "12646  explosion   airburst     647  test   \n",
      "12647  explosion   blowback     647  test   \n",
      "12648  explosion   big bang     647  test   \n",
      "12649  explosion  inflation     647  test   \n",
      "12650  explosion      blast     647  test   \n",
      "\n",
      "                                       father_definition  \\\n",
      "12646  a violent release of energy caused by a chemic...   \n",
      "12647  a violent release of energy caused by a chemic...   \n",
      "12648  a violent release of energy caused by a chemic...   \n",
      "12649  a violent release of energy caused by a chemic...   \n",
      "12650  a violent release of energy caused by a chemic...   \n",
      "\n",
      "                                        child_definition  \n",
      "12646                     an explosion in the atmosphere  \n",
      "12647  the backward escape of gases and unburned gunp...  \n",
      "12648  (cosmology) the cosmic explosion that is hypot...  \n",
      "12649  (cosmology) a brief exponential expansion of t...  \n",
      "12650                      an explosion (as of dynamite)  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-a31ad0ad574a>:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_bansal_df[\"father\"] = filtered_bansal_df[\"father\"].apply(lambda x: x.replace(\"_$_\", \" \"))\n",
      "<ipython-input-2-a31ad0ad574a>:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_bansal_df[\"child\"] = filtered_bansal_df[\"child\"].apply(lambda x: x.replace(\"_$_\", \" \"))\n",
      "<ipython-input-2-a31ad0ad574a>:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_bansal_df[\"father_definition\"] = father_defs\n",
      "<ipython-input-2-a31ad0ad574a>:86: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_bansal_df[\"child_definition\"] = child_defs\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import networkx as nx\n",
    "import random\n",
    "import json\n",
    "\n",
    "input_ctpfile = \"datasets/definitions_bansal.json\"\n",
    "input_bansalfile = \"datasets/bansal14_trees.csv\"\n",
    "\n",
    "output_mixfiles = [\n",
    "    \"properties/bansal_with_defs_train.json\",\n",
    "    \"properties/bansal_with_defs_dev.json\",\n",
    "    \"properties/bansal_with_defs_test.json\",\n",
    "]\n",
    "\n",
    "\n",
    "# Handlers JSON\n",
    "def load_json(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def save_json(myjson, filepath):\n",
    "    jstring = json.dumps(myjson)\n",
    "    jfile = open(filepath, \"w\")\n",
    "    jfile.write(jstring)\n",
    "    jfile.close()\n",
    "\n",
    "\n",
    "# Align subtaxonomies with definition, to extend initial file\n",
    "def create_mix_bansal_ctp(bansalfile, ctpfile, outputfiles, splits=[], datapath_base='.'):\n",
    "    \"\"\"\n",
    "    Align samples subtaxonomies from Bansal dataset with the oracle definitions given in the CTP paper.\n",
    "    Input: Bansal file, CTP file (bansal with definitions), splits to use: normally train/dev/test, datapath_base: common data directory\n",
    "    Output: None. Save json (from dataframes) files for each split in the outputfiles paths.\n",
    "    \"\"\"\n",
    "    bansal_df = pd.read_csv(bansalfile, names=[\"father\",'child', 'treeid', 'split'])\n",
    "    definitions_json = load_json(ctpfile)\n",
    "\n",
    "    dictionary_words = {}\n",
    "    for treeid,defs in definitions_json.items():\n",
    "        for term,defi in defs.items():\n",
    "            tmp_key = (term,int(treeid))\n",
    "            defs = dictionary_words.get(tmp_key,set())\n",
    "            defs.add(defi)\n",
    "            dictionary_words[tmp_key] = defs\n",
    "\n",
    "    print(\"Check if multiple definitions are present.\")\n",
    "    cnt = 0\n",
    "    for w,defs in dictionary_words.items():\n",
    "        if len(defs) > 1:\n",
    "            print(w, defs)\n",
    "            cnt += 1\n",
    "    print(\"Total words\", len(dictionary_words), \". Words with more than 1 definition \", cnt)\n",
    "\n",
    "    # Creates separate files for train/dev/test with definitions\n",
    "    for split, outputfile in zip(splits, outputfiles):\n",
    "        filtered_bansal_df = bansal_df[bansal_df[\"split\"]==split] # Filter bansal split\n",
    "        # Some stats about the json file\n",
    "        print(\"########   \", split, \" ###########\")\n",
    "        # use term definition as oracle glosses (from wordnet)\n",
    "        print(\"Number of entries: \", len(filtered_bansal_df) )\n",
    "\n",
    "        filtered_bansal_df[\"father\"] = filtered_bansal_df[\"father\"].apply(lambda x: x.replace(\"_$_\", \" \"))\n",
    "        filtered_bansal_df[\"child\"] = filtered_bansal_df[\"child\"].apply(lambda x: x.replace(\"_$_\", \" \"))\n",
    "\n",
    "        #print(display(filtered_bansal_df.head()))\n",
    "        father_defs = []\n",
    "        child_defs = []\n",
    "        # Mix datasets\n",
    "        for index, row in filtered_bansal_df.iterrows():\n",
    "            key = (row[\"father\"], int(row[\"treeid\"]) )\n",
    "            defs = dictionary_words.get(key, None)\n",
    "            if defs is None:\n",
    "                print(\"Not found\", key)\n",
    "            else:\n",
    "                father_defs.append(list(defs)[0])\n",
    "            key = (row[\"child\"], int(row[\"treeid\"]))\n",
    "            defs = dictionary_words.get(key, None)\n",
    "            if defs is None:\n",
    "                print(\"Not found\", key)\n",
    "            else:\n",
    "                child_defs.append(list(defs)[0])\n",
    "        # Add new columns\n",
    "        filtered_bansal_df[\"father_definition\"] = father_defs\n",
    "        filtered_bansal_df[\"child_definition\"] = child_defs\n",
    "        print(filtered_bansal_df.head()) # Print a bit so we now it is ok :)\n",
    "        # Save json\n",
    "        filtered_bansal_df.to_json(outputfile,orient=\"index\")\n",
    "\n",
    "\n",
    "\n",
    "# Only run once, aligns words with definitions from subtrees\n",
    "# 3 datasets on English (train,dev,test)\n",
    "#_context are extracted from Wikipedia and others. And reorder according to relevance based on Glove embeddings similarity on CTP\n",
    "#_definition are the ones provided in WordNet\n",
    "#create_mix_bansal_ctp(input_bansalfile, input_ctpfile, output_mixfiles, splits=[\"train\", \"dev\", \"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4da0178",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Generate Properties\n",
    "With the generated files construct trees based on Bansal subtaxonomies, and sample all the possible patterns found in a full tree of height=3.\n",
    "\n",
    "Adapted for the WordNet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "435a1bfd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "import math\n",
    "import subprocess\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import random\n",
    "import json\n",
    "\n",
    "def get_trees_from_jsondf(inputfile, ):\n",
    "    df = pd.read_json(inputfile, orient=\"index\")\n",
    "    # Iterate by subtrees, create directed graph + collect definitions\n",
    "    subtrees = {} # key:value -> (id_tree): {definitions:{}, graph:}\n",
    "    for tid in range(min(df[\"treeid\"]), max(df[\"treeid\"])+1): # For each subtree\n",
    "        filtered_df = df[df[\"treeid\"]==tid]\n",
    "        # Retrieve definitions in this subtree\n",
    "        dictionary_defs, G = {}, nx.DiGraph()\n",
    "        for idx,row in filtered_df.iterrows():\n",
    "            dictionary_defs[row['father']] = row['father_definition']\n",
    "            dictionary_defs[row['child']] = row['child_definition']\n",
    "            G.add_edge(row['father'], row['child'])\n",
    "\n",
    "        subtrees[tid] = {'definitions':dictionary_defs, 'graph':G}\n",
    "        #print(\"Root\", [n for n,d in G.in_degree() if d==0] )\n",
    "    return subtrees\n",
    "\n",
    "\n",
    "\n",
    "def generate_hard_negatives(node_left, node_right, rel_root, G):\n",
    "    # Negative triplet (change intermediate (child_node) entity)\n",
    "    negative_triplets = []\n",
    "    for node_x in G.predecessors(rel_root): # fathers of A\n",
    "        negative_triplets.append((node_left, node_x, node_right,-1))\n",
    "        for node_y in G.successors(node_x): \n",
    "            if node_y == rel_root:\n",
    "                continue\n",
    "            # all descendants not in subtree\n",
    "            negative_triplets.append((node_left, node_y, node_right,-2))\n",
    "            # This last level could be removed (are more difficult?)\n",
    "            for node_z in nx.descendants(G,node_y):\n",
    "                negative_triplets.append((node_left,node_z,node_right,-3))\n",
    "    return negative_triplets\n",
    "\n",
    "\n",
    "\n",
    "def generate_soft_negatives(node_left, node_right,tree_id, subtrees):\n",
    "    # Return negatives out of the current subtree\n",
    "    all_tids = subtrees.keys()\n",
    "    list_names = []\n",
    "    negative_triplets = []\n",
    "    random_tids = random.sample(list(all_tids),15)\n",
    "    for r_tid in random_tids:\n",
    "        if r_tid==tree_id:\n",
    "            continue\n",
    "        node_names = [(k,v) for k,v in subtrees[r_tid]['definitions'].items()]\n",
    "        list_names.extend(random.sample(list(node_names),5))\n",
    "    #if len(list_names)==0:\n",
    "    #    print(node_left, node_right, random_tids)\n",
    "    final_list = random.sample(list(list_names),10) # Generate max 10 randoms\n",
    "    for (name,defs) in final_list:\n",
    "        negative_triplets.append((node_left,name,node_right,-4,defs))\n",
    "    return negative_triplets\n",
    "\n",
    "\n",
    "def generate_soft_positives(node_left, node_right,tree_id, subtrees, minsample=5):\n",
    "    all_tids = subtrees.keys()\n",
    "    list_names = []\n",
    "    negative_triplets = []\n",
    "    random_tids = random.sample(list(all_tids),min(minsample,len(all_tids))) # before , 1st run was minsample=15\n",
    "    for r_tid in random_tids:\n",
    "        if r_tid==tree_id:\n",
    "            continue\n",
    "        node_names = [(k,v) for k,v in subtrees[r_tid]['definitions'].items()]\n",
    "        list_names.extend(random.sample(list(node_names),min(minsample,len(node_names))))\n",
    "    #if len(list_names)==0:\n",
    "    #    print(node_left, node_right, random_tids)\n",
    "    final_list = random.sample(list(list_names),min(minsample,len(list_names))) # Generate max 10 randoms\n",
    "    for (name,defs) in final_list:\n",
    "        negative_triplets.append((node_left,node_right,name,0,defs))\n",
    "    return negative_triplets\n",
    "\n",
    "\n",
    "def generate_triplets(property_generator):\n",
    "    \n",
    "    def wrapper(subtrees):\n",
    "        only_soff_pos = True\n",
    "        # generate properties from the graph\n",
    "        all_triplets = [] # treeid, e1,e2,e3, def_1,def_2,def_3,valid,property\n",
    "        for tree_id, info_tree in subtrees.items(): # for each subtree\n",
    "            G = info_tree['graph']\n",
    "            definitions = info_tree['definitions']\n",
    "            positive_triplets = list()\n",
    "            negative_triplets = list()\n",
    "            soft_negatives_triplets = list()\n",
    "            soft_positive_triplets = list()\n",
    "            #print(G.nodes())\n",
    "            # Iterator of triplets, it returns 3 entities + 1 the grand ancestor\n",
    "            # We use the grand ancestor (node_anc) to draw entities out of the mini subtree\n",
    "            iter_prop = property_generator(G)\n",
    "            for (node_d,node_b,node_a, node_anc) in iter_prop:\n",
    "                positive_triplets.append((node_d, node_b, node_a,1)) # Tag 1 for hard negative\n",
    "                if not only_soff_pos:\n",
    "                    hard_negatives = generate_hard_negatives(node_d,node_a, node_anc, G)\n",
    "                    negative_triplets.extend(hard_negatives) # tags -1,-2,-3 for different positions from negatives\n",
    "                    soft_negatives = generate_soft_negatives(node_d, node_a,tree_id, subtrees) #tag -4\n",
    "                    soft_negatives_triplets.extend(soft_negatives)\n",
    "\n",
    "                soft_positives = generate_soft_positives(node_d, node_b,tree_id, subtrees) #tag 0, positive triplets with 3rd entity easier\n",
    "                soft_positive_triplets.extend(soft_positives)\n",
    "                soft_positives = generate_soft_positives(node_d, node_a,tree_id, subtrees) #tag 0, positive triplets with 3rd entity easier\n",
    "                soft_positive_triplets.extend(soft_positives)\n",
    "\n",
    "            # Format for dataframe\n",
    "            for triplet in positive_triplets:\n",
    "                all_triplets.append([tree_id, triplet[0],triplet[1],triplet[2],\n",
    "                                    definitions[triplet[0]],\n",
    "                                    definitions[triplet[1]],\n",
    "                                    definitions[triplet[2]],\n",
    "                                    triplet[3]])\n",
    "            if not only_soff_pos:\n",
    "                for triplet in negative_triplets:\n",
    "                    all_triplets.append([tree_id, triplet[0],triplet[1],triplet[2],\n",
    "                                        definitions[triplet[0]],\n",
    "                                        definitions[triplet[1]],\n",
    "                                        definitions[triplet[2]],\n",
    "                                        triplet[3]])\n",
    "                for triplet in soft_negatives_triplets:\n",
    "                    all_triplets.append([tree_id, triplet[0],triplet[1],triplet[2],\n",
    "                                        definitions[triplet[0]],\n",
    "                                        triplet[4],\n",
    "                                        definitions[triplet[2]],\n",
    "                                        triplet[3]])\n",
    "\n",
    "            for triplet in soft_positive_triplets:\n",
    "                all_triplets.append([tree_id, triplet[0],triplet[1],triplet[2],\n",
    "                                    definitions[triplet[0]],\n",
    "                                    definitions[triplet[1]],\n",
    "                                    triplet[4],\n",
    "                                    triplet[3]])\n",
    "\n",
    "        dataframe_prop = pd.DataFrame(all_triplets,columns=['tree_id', 'ent_1','ent_2','ent_3','def_1','def_2','def_3','valid'])\n",
    "        dataframe_prop.drop_duplicates(inplace=True)\n",
    "        for i in [1,0,-1,-2,-3,-4]:\n",
    "            print(i, len(dataframe_prop[dataframe_prop['valid']==i]))\n",
    "            #(6397, 20472)\n",
    "        return dataframe_prop\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "\n",
    "@generate_triplets\n",
    "def it_property1(G):\n",
    "    for node_a in G.nodes():\n",
    "        for node_b in G.successors(node_a):\n",
    "            for node_d in G.successors(node_b):\n",
    "                yield (node_d,node_b,node_a, node_a)\n",
    "                \n",
    "@generate_triplets\n",
    "def it_property2(G):\n",
    "    for node_a in G.nodes():\n",
    "        for node_b in G.successors(node_a):\n",
    "            for node_d in G.successors(node_b):\n",
    "                for node_e in G.successors(node_b):\n",
    "                    if node_e == node_d:\n",
    "                        continue\n",
    "                    yield (node_d,node_b,node_e, node_a)\n",
    "                    \n",
    "@generate_triplets\n",
    "def it_property3(G):\n",
    "    for node_a in G.nodes():\n",
    "        for node_b in G.successors(node_a):\n",
    "            for node_d in G.successors(node_b):\n",
    "                for node_c in G.successors(node_a):\n",
    "                    if node_b==node_c:\n",
    "                        continue\n",
    "                    yield (node_d, node_b, node_c,node_a)\n",
    "                    \n",
    "\n",
    "@generate_triplets\n",
    "def it_property4(G):\n",
    "    for node_a in G.nodes():\n",
    "        for node_b in G.successors(node_a):\n",
    "            for node_d in G.successors(node_b):\n",
    "                for node_c in G.successors(node_a):\n",
    "                    if node_b==node_c:\n",
    "                        continue\n",
    "                    for node_f in G.successors(node_c):\n",
    "                        yield (node_d, node_b, node_f,node_a)\n",
    "                    \n",
    "\n",
    "@generate_triplets\n",
    "def it_property5(G):\n",
    "    for node_a in G.nodes():\n",
    "        for node_b in G.successors(node_a):\n",
    "            for node_d in G.successors(node_b):\n",
    "                for node_e in G.successors(node_b):\n",
    "                    if node_d == node_e:\n",
    "                        continue\n",
    "                    yield (node_d, node_a, node_e,node_a)\n",
    "                    \n",
    "@generate_triplets\n",
    "def it_property6(G):\n",
    "    for node_a in G.nodes():\n",
    "        for node_b in G.successors(node_a):\n",
    "            for node_c in G.successors(node_a):\n",
    "                if node_b == node_c:\n",
    "                    continue\n",
    "                for node_d in G.successors(node_b):\n",
    "                    yield (node_d, node_a, node_c,node_a)\n",
    "                    \n",
    "\n",
    "@generate_triplets\n",
    "def it_property7(G):\n",
    "    for node_a in G.nodes():\n",
    "        for node_b in G.successors(node_a):\n",
    "            for node_d in G.successors(node_b):\n",
    "                for node_c in G.successors(node_a):\n",
    "                    if node_b == node_c:\n",
    "                        continue\n",
    "                    for node_f in G.successors(node_c):\n",
    "                        yield (node_d, node_a, node_f,node_a)\n",
    "                    \n",
    "@generate_triplets\n",
    "def it_property8(G):\n",
    "    for node_a in G.nodes():\n",
    "        for node_b in G.successors(node_a):\n",
    "            for node_d in G.successors(node_b):\n",
    "                for node_e in G.successors(node_b):\n",
    "                    if node_d == node_e:\n",
    "                        continue\n",
    "                    for node_c in G.successors(node_a):\n",
    "                        if node_c == node_b:\n",
    "                            continue\n",
    "                        \n",
    "                        yield (node_d, node_e, node_c,node_a)\n",
    "\n",
    "@generate_triplets\n",
    "def it_property9(G):\n",
    "    for node_a in G.nodes():\n",
    "        for node_b in G.successors(node_a):\n",
    "            for node_d in G.successors(node_b):\n",
    "                for node_e in G.successors(node_b):\n",
    "                    if node_d == node_e:\n",
    "                        continue\n",
    "                    for node_c in G.successors(node_a):\n",
    "                        if node_c == node_b:\n",
    "                            continue\n",
    "                        for node_f in G.successors(node_c):\n",
    "                            yield (node_d, node_e, node_f,node_a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a1108f9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "properties/bansal_with_defs_train.json\n",
      "1 6397\n",
      "0 63970\n",
      "-1 0\n",
      "-2 0\n",
      "-3 0\n",
      "-4 0\n",
      "1 28912\n",
      "0 288751\n",
      "-1 0\n",
      "-2 0\n",
      "-3 0\n",
      "-4 0\n",
      "1 28912\n",
      "0 288724\n",
      "-1 0\n",
      "-2 0\n",
      "-3 0\n",
      "-4 0\n",
      "1 31116\n",
      "0 310707\n",
      "-1 0\n",
      "-2 0\n",
      "-3 0\n",
      "-4 0\n",
      "1 31116\n",
      "0 310714\n",
      "-1 0\n",
      "-2 0\n",
      "-3 0\n",
      "-4 0\n",
      "1 39505\n",
      "0 394507\n",
      "-1 0\n",
      "-2 0\n",
      "-3 0\n",
      "-4 0\n",
      "1 39505\n",
      "0 394465\n",
      "-1 0\n",
      "-2 0\n",
      "-3 0\n",
      "-4 0\n",
      "1 126196\n",
      "0 1258866\n",
      "-1 0\n",
      "-2 0\n",
      "-3 0\n",
      "-4 0\n",
      "1 159848\n",
      "0 1594615\n",
      "-1 0\n",
      "-2 0\n",
      "-3 0\n",
      "-4 0\n",
      "properties/bansal_with_defs_dev.json\n",
      "1 1443\n",
      "0 14430\n",
      "-1 0\n",
      "-2 0\n",
      "-3 0\n",
      "-4 0\n",
      "1 5744\n",
      "0 57216\n",
      "-1 0\n",
      "-2 0\n",
      "-3 0\n",
      "-4 0\n",
      "1 5744\n",
      "0 57214\n",
      "-1 0\n",
      "-2 0\n",
      "-3 0\n",
      "-4 0\n",
      "1 8540\n",
      "0 84785\n",
      "-1 0\n",
      "-2 0\n",
      "-3 0\n",
      "-4 0\n",
      "1 8540\n",
      "0 84762\n",
      "1-1  93470\n",
      "\n",
      "-2 0\n",
      "-3 0\n",
      "-4 00\n",
      " 92941\n",
      "-1 0\n",
      "-2 0\n",
      "-3 0\n",
      "-4 0\n",
      "1 9347\n",
      "0 92933\n",
      "-1 0\n",
      "-2 0\n",
      "-3 0\n",
      "-4 0\n",
      "1 34066\n",
      "0 337169\n",
      "-1 0\n",
      "-2 0\n",
      "-3 0\n",
      "-4 0\n",
      "1 37624\n",
      "0 372397\n",
      "-1 0\n",
      "-2 0\n",
      "-3 0\n",
      "-4 0\n",
      "properties/bansal_with_defs_test.json\n",
      "1 1435\n",
      "0 14350\n",
      "-1 0\n",
      "-2 0\n",
      "-3 0\n",
      "-4 0\n",
      "1 6522\n",
      "0 64826\n",
      "-1 0\n",
      "-2 0\n",
      "-3 0\n",
      "-4 0\n",
      "1 6522\n",
      "0 64869\n",
      "-1 0\n",
      "-2 0\n",
      "-3 0\n",
      "-4 0\n",
      "1 7658\n",
      "0 76108\n",
      "-1 0\n",
      "-2 0\n",
      "-3 0\n",
      "-4 0\n",
      "1 8273\n",
      "0 82248\n",
      "-1 0\n",
      "-2 0\n",
      "-3 0\n",
      "-4 0\n",
      "1 7658\n",
      "0 76072\n",
      "-1 0\n",
      "-2 0\n",
      "-3 0\n",
      "-4 0\n",
      "1 8273\n",
      "0 82275\n",
      "-1 0\n",
      "-2 0\n",
      "-3 0\n",
      "-4 0\n",
      "1 31746\n",
      "0 313969\n",
      "-1 0\n",
      "-2 0\n",
      "-3 0\n",
      "-4 0\n",
      "1 33160\n",
      "0 328443\n",
      "-1 0\n",
      "-2 0\n",
      "-3 0\n",
      "-4 0\n"
     ]
    }
   ],
   "source": [
    "# Parallel generation of properties\n",
    "\n",
    "output_folder='properties'\n",
    "output_mixfiles = [\n",
    "    \"properties/bansal_with_defs_train.json\",\n",
    "    \"properties/bansal_with_defs_dev.json\",\n",
    "    \"properties/bansal_with_defs_test.json\",\n",
    "]\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "\n",
    "\n",
    "def run_proc(idx, ifile,_mysubtrees):\n",
    "    all_properties = [it_property1,it_property2,it_property3,it_property4,it_property5,it_property6,it_property7,it_property8,it_property9]\n",
    "    all_idxs = list(range(9))\n",
    "    #all_properties = [it_property1,it_property2,it_property3,it_property5,it_property6,it_property8,it_property9]\n",
    "    #all_idxs = [0,1,2,4,5,7,8]\n",
    "    prop=all_properties[idx]\n",
    "    myidx = all_idxs[idx]\n",
    "    ofilename = ifile.replace(\".json\", \"_prop_\"+str(myidx)+\".json\")\n",
    "    newdf = prop(_mysubtrees)\n",
    "    newdf.to_json(ofilename, orient=\"index\")\n",
    "\n",
    "\n",
    "def main_properties_generator():\n",
    "    for ifile in output_mixfiles:\n",
    "        print(ifile)\n",
    "        _mysubtrees = get_trees_from_jsondf(ifile)\n",
    "        #run_proc(0,ifile,_mysubtrees)\n",
    "        n = 9 # 9 properties\n",
    "        p = Pool(n)\n",
    "        for i in range(n):\n",
    "            p.apply_async(run_proc, args=(i, ifile,_mysubtrees))\n",
    "        p.close()\n",
    "        p.join()\n",
    "        \n",
    "\n",
    "\n",
    "main_properties_generator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "988af55c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Property 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-4f7baf3b38ab>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard_pos_df['prop'] = prop+1\n",
      "<ipython-input-27-4f7baf3b38ab>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  soft_pos_df['prop'] = prop+1 # Add new column to identify property\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hard triplets 6397\n",
      "Total soft triplets 63970\n",
      "Property 2\n",
      "Total hard triplets 32688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-4f7baf3b38ab>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  soft_pos_df['prop'] = prop+1 # Add new column to identify property\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total soft triplets 32688\n",
      "Property 3\n",
      "Total hard triplets 36156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-4f7baf3b38ab>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  soft_pos_df['prop'] = prop+1 # Add new column to identify property\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total soft triplets 36156\n",
      "Property 5\n",
      "Total hard triplets 32688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-4f7baf3b38ab>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  soft_pos_df['prop'] = prop+1 # Add new column to identify property\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total soft triplets 32688\n",
      "Property 6\n",
      "Total hard triplets 36156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-4f7baf3b38ab>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  soft_pos_df['prop'] = prop+1 # Add new column to identify property\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total soft triplets 36156\n",
      "Property 8\n",
      "Total hard triplets 17909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-4f7baf3b38ab>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  soft_pos_df['prop'] = prop+1 # Add new column to identify property\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total soft triplets 17909\n",
      "Property 9\n",
      "Total hard triplets 13124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-4f7baf3b38ab>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  soft_pos_df['prop'] = prop+1 # Add new column to identify property\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total soft triplets 13124\n",
      "407809\n",
      "Final  315920\n",
      "1 49623\n",
      "2 47411\n",
      "3 54858\n",
      "4 0\n",
      "5 47431\n",
      "6 54838\n",
      "7 0\n",
      "8 35638\n",
      "9 26121\n"
     ]
    }
   ],
   "source": [
    "# To sample up to 8x negatives\n",
    "# mydf = sample_mydf_v2(\"bansal_with_defs_trainprop_{prop}.json\", frac1=6, frac2=0.65, frac3=1,frac_pos=5, soft=True)\n",
    "def sample_mydf_v2(filestr, frac1=5, frac2=0.65, frac3=1, frac_pos=30,soft=False):\n",
    "    sampled_df = []\n",
    "    for prop in [0,1,2,4,5,7,8]:\n",
    "        print(\"Property\", prop+1)\n",
    "        _propfile = filestr.format(prop=str(prop))\n",
    "        df = pd.read_json(_propfile, orient=\"index\") # complete dataframe\n",
    "\n",
    "        hard_pos_df = df[df['valid']==1] # Filter hard positives\n",
    "\n",
    "        if prop ==0: # If P1 (0) use everything, it's the smallest!\n",
    "            hard_pos_df['prop'] = prop+1\n",
    "            sampled_df.append(hard_pos_df)\n",
    "        else:\n",
    "            # Random sample fixing 2 entities, the if is because there are more triplets for prop 8,9\n",
    "            if prop<7:\n",
    "                sdf = hard_pos_df.groupby(['tree_id','ent_1','ent_2']).sample(n=frac1,random_state=42, replace=True)\n",
    "            else:\n",
    "                sdf = hard_pos_df.groupby(['tree_id','ent_1','ent_2']).sample(n=frac3,random_state=42, replace=True)\n",
    "                sdf = sdf.sample(frac=frac2, random_state=42)\n",
    "            sdf['prop'] = prop+1 # Add new column to identify property\n",
    "            sampled_df.append(sdf)\n",
    "        print(\"Total hard triplets\",len(sampled_df[-1]))\n",
    "        del hard_pos_df\n",
    "        if soft: # sample soft positives too\n",
    "            soft_pos_df = df[df['valid']==0]# Filter soft positives\n",
    "            soft_pos_df['prop'] = prop+1 # Add new column to identify property\n",
    "            new_soft = soft_pos_df.groupby(['tree_id','ent_1','ent_2']).sample(n=frac_pos,random_state=42, replace=True)\n",
    "\n",
    "            sample_size = 1\n",
    "            if prop==0:\n",
    "                sample_size = 10 #80 for x30\n",
    "            if prop==2 or prop==5:\n",
    "                sample_size = 1#5 for x30\n",
    "            new_soft = new_soft.sample(n=min(len(new_soft),len(sampled_df[-1])*sample_size),random_state=42)\n",
    "            new_soft['prop'] = prop+1\n",
    "            sampled_df.append(new_soft)\n",
    "            print(\"Total soft triplets\",len(sampled_df[-1]))\n",
    "            del new_soft\n",
    "        del df\n",
    "    final_df = pd.concat(sampled_df)\n",
    "    print(len(final_df))\n",
    "    final_df.drop_duplicates(['tree_id','ent_1','ent_2','ent_3'], inplace=True)\n",
    "    print(\"Final \",len(final_df))\n",
    "    return final_df\n",
    "\n",
    "mydf = sample_mydf_v2(\"properties/bansal_with_defs_train_prop_{prop}.json\", frac1=6, frac2=0.65, frac3=1,frac_pos=5, soft=True)\n",
    "for prop in range(9):\n",
    "    print(prop+1, len(mydf[mydf['prop']==(prop+1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6791072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove prop 5 since we are not sure\n",
    "new_df = mydf[mydf['prop']!=5]\n",
    "new_df.reset_index().to_json( \"properties/train_hard_soft_neg_sample_5x_p123689.json\", orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dac75e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1 43226\n",
      "2 30618\n",
      "3 34148\n",
      "4 0\n",
      "5 0\n",
      "6 34131\n",
      "7 0\n",
      "8 17729\n",
      "9 12998\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "# Consider only uncle (too many cases if we add nephew too!, that's why 4 and 7 are 0)\n",
    "ndf = new_df[new_df['valid']==0]\n",
    "for i in range(10):\n",
    "    print(i, len(ndf[ndf['prop']==i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9218f3a8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-98392f9c6a54>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard_pos['prop'] = prop+1 # Add new column to identify property\n",
      "<ipython-input-30-98392f9c6a54>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard_pos['prop'] = prop+1 # Add new column to identify property\n",
      "<ipython-input-30-98392f9c6a54>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard_pos['prop'] = prop+1 # Add new column to identify property\n",
      "<ipython-input-30-98392f9c6a54>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard_pos['prop'] = prop+1 # Add new column to identify property\n",
      "<ipython-input-30-98392f9c6a54>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard_pos['prop'] = prop+1 # Add new column to identify property\n",
      "<ipython-input-30-98392f9c6a54>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard_pos['prop'] = prop+1 # Add new column to identify property\n",
      "<ipython-input-30-98392f9c6a54>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard_pos['prop'] = prop+1 # Add new column to identify property\n",
      "<ipython-input-30-98392f9c6a54>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard_pos['prop'] = prop+1 # Add new column to identify property\n",
      "<ipython-input-30-98392f9c6a54>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard_pos['prop'] = prop+1 # Add new column to identify property\n"
     ]
    }
   ],
   "source": [
    "# Make only hard positive test file\n",
    "test_df = []\n",
    "_filestr = \"properties/bansal_with_defs_test_prop_{prop}.json\"\n",
    "for prop in range(9):\n",
    "    _propfile = _filestr.format(prop=str(prop))\n",
    "    df = pd.read_json(_propfile, orient=\"index\") # complete dataframe\n",
    "    hard_pos = df[df['valid']==1] # Filter hard positives\n",
    "    hard_pos['prop'] = prop+1 # Add new column to identify property\n",
    "    test_df.append(hard_pos)\n",
    "final_df = pd.concat(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b595210",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1435\n",
      "2 7658\n",
      "3 8273\n",
      "4 6522\n",
      "5 7658\n",
      "6 8273\n",
      "7 6522\n",
      "8 33160\n",
      "9 31746\n"
     ]
    }
   ],
   "source": [
    "for prop in range(9):\n",
    "    print(prop+1, len(final_df[final_df['prop']==(prop+1)]))\n",
    "final_df.reset_index().to_json(\"properties/test_hard_neg.json\", orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "51c09b77",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Property 1\n",
      "Property 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-ac3825cd3522>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard_pos_df['prop'] = prop+1 # Add new column to identify property\n",
      "<ipython-input-37-ac3825cd3522>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard_pos_df['prop'] = prop+1 # Add new column to identify property\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Property 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-ac3825cd3522>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard_pos_df['prop'] = prop+1 # Add new column to identify property\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Property 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-ac3825cd3522>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard_pos_df['prop'] = prop+1 # Add new column to identify property\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Property 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-ac3825cd3522>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard_pos_df['prop'] = prop+1 # Add new column to identify property\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Property 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-ac3825cd3522>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard_pos_df['prop'] = prop+1 # Add new column to identify property\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Property 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-ac3825cd3522>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard_pos_df['prop'] = prop+1 # Add new column to identify property\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Property 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-ac3825cd3522>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard_pos_df['prop'] = prop+1 # Add new column to identify property\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Property 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-ac3825cd3522>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard_pos_df['prop'] = prop+1 # Add new column to identify property\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20579\n",
      "18291\n",
      "1 1443\n",
      "2 2016\n",
      "3 2401\n",
      "4 1951\n",
      "5 2016\n",
      "6 2401\n",
      "7 1951\n",
      "8 2208\n",
      "9 1904\n"
     ]
    }
   ],
   "source": [
    "# Dev\n",
    "\n",
    "def sample_mydf(filestr, frac1=5, frac2=0.65, frac3=1, soft=False):\n",
    "    sampled_df = []\n",
    "    for prop in range(9):\n",
    "        print(\"Property\", prop+1)\n",
    "        _propfile = filestr.format(prop=str(prop))\n",
    "        df = pd.read_json(_propfile, orient=\"index\") # complete dataframe\n",
    "\n",
    "        hard_pos_df = df[df['valid']==1] # Filter hard positives\n",
    "        hard_pos_df['prop'] = prop+1 # Add new column to identify property\n",
    "\n",
    "        if prop ==0: # If P1 (0) use everything, it's the smallest!\n",
    "            sampled_df.append(hard_pos_df)\n",
    "        else:\n",
    "            # Random sample fixing 2 entities, the if is because there are more triplets for prop 8,9\n",
    "            if prop<7:\n",
    "                sdf = hard_pos_df.groupby(['tree_id','ent_1','ent_2']).sample(n=frac1,random_state=42, replace=True)\n",
    "            else:\n",
    "                sdf = hard_pos_df.groupby(['tree_id','ent_1','ent_2']).sample(n=frac3,random_state=42, replace=True)\n",
    "                sdf = sdf.sample(frac=frac2, random_state=42)\n",
    "            sampled_df.append(sdf)\n",
    "        if soft: # sample soft positives too\n",
    "            soft_pos_df = df[df['valid']==0]# Filter soft positives\n",
    "            soft_pos_df['prop'] = prop+1 # Add new column to identify property\n",
    "            new_soft = soft_pos_df.groupby(['tree_id','ent_1','ent_2']).sample(n=frac1,random_state=42, replace=True)\n",
    "            sample_size = 4\n",
    "            if prop==0:\n",
    "                sample_size = 6#10\n",
    "            new_soft = new_soft.sample(n=len(sampled_df[-1])*sample_size,random_state=42)\n",
    "            sampled_df.append(new_soft)\n",
    "    final_df = pd.concat(sampled_df)\n",
    "    print(len(final_df))\n",
    "    final_df.drop_duplicates(['tree_id','ent_1','ent_2','ent_3'], inplace=True)\n",
    "    print(len(final_df))\n",
    "    return final_df\n",
    "\n",
    "# Dev\n",
    "mydf = sample_mydf(\"properties/bansal_with_defs_dev_prop_{prop}.json\", frac1=2, frac2=0.4)\n",
    "for prop in range(9):\n",
    "    print(prop+1, len(mydf[mydf['prop']==(prop+1)]))\n",
    "\n",
    "\n",
    "    \n",
    "mydf.reset_index().to_json( \"properties/dev_hard_neg.json\", orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e537d98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1443\n",
      "2 2016\n",
      "3 2401\n",
      "4 1951\n",
      "5 2016\n",
      "6 2401\n",
      "7 1951\n",
      "8 2208\n",
      "9 1904\n"
     ]
    }
   ],
   "source": [
    "#Stats\n",
    "for prop in range(9):\n",
    "    print(prop+1, len(mydf[mydf['prop']==(prop+1)]))\n",
    "#final_df.reset_index().to_json(\"properties/dev_hard_neg.json\", orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf1af68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files to use\n",
    "# Train: hierarchy_evaluation2023/data_generator/properties/train_hard_soft_neg_sample_5x_p123689.json -> train_hard_soft_neg.json\n",
    "# Dev: hierarchy_evaluation2023/data_generator/properties/dev_hard_neg.json\n",
    "# Test: hierarchy_evaluation2023/data_generator/properties/test_hard_neg.json\n",
    "!mv ~/hierarchy_evaluation2023/data_generator/properties/train_hard_soft_neg_sample_5x_p123689.json ~/hierarchy_evaluation2023/data_generator/properties/train_hard_soft_neg.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac9ba32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
